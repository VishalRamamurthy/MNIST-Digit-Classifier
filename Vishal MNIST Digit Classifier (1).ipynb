{
 "cells": [
  {
   "cell_type": "raw",
   "id": "3d7349fd-8cf0-4ee5-986a-ded3b90bdf26",
   "metadata": {},
   "source": [
    "pip install numpy pandas opencv-python scikit-image scikit-learn"
   ]
  },
  {
   "cell_type": "raw",
   "id": "d1595c58-1f08-44a5-b5e0-da3bc263b01a",
   "metadata": {},
   "source": [
    "pip install tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "38da01d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Necessary Datasets (added comments to the whole code)\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import cv2\n",
    "from skimage.feature import hog\n",
    "from sklearn.datasets import fetch_openml\n",
    "from scipy import ndimage\n",
    "from skimage.measure import label, regionprops\n",
    "from skimage import morphology\n",
    "import matplotlib.pyplot as plt\n",
    "from skimage import morphology, measure\n",
    "from skimage.transform import probabilistic_hough_line\n",
    "from keras.datasets import mnist\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "21ce8de7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(70000, 784)\n",
      "(70000,)\n"
     ]
    }
   ],
   "source": [
    "# Import the MNIST dataset\n",
    "mnist = fetch_openml('mnist_784', version=1)\n",
    "X = mnist.data\n",
    "y = mnist.target.astype(int)\n",
    "\n",
    "print(f\"{X.shape}\")\n",
    "print(f\"{y.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "018b8969-923e-4710-9c07-d3b49bd9fdad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Skeletonization\n",
    "def skeletonize_image(image):\n",
    "    binary_image = image > np.mean(image)\n",
    "    \n",
    "    skeleton = morphology.skeletonize(binary_image)\n",
    "    \n",
    "    return skeleton"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "afbb1b30",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of Dark Pixels\n",
    "def num_dark_pixels(image):\n",
    "    return np.sum(image < 128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7cb55e40",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vertical Symmetry\n",
    "def vertical_symmetry(image):\n",
    "    width = image.shape[1]\n",
    "    left_half = image[:, :width//2]\n",
    "    right_half = image[:, width//2:]\n",
    "    right_half_flipped = np.flip(right_half, axis=1)\n",
    "    return np.sum(left_half == right_half_flipped) / left_half.size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4f421aa3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Horizontal Symmetry\n",
    "def horizontal_symmetry(image):\n",
    "    height = image.shape[0]\n",
    "    top_half = image[:height//2, :]\n",
    "    bottom_half = image[height//2:, :]\n",
    "    bottom_half_flipped = np.flip(bottom_half, axis=0)\n",
    "    return np.sum(top_half == bottom_half_flipped) / top_half.size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4566d304-b7a8-4126-89e9-eee840628074",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of Corners\n",
    "def compute_corners(image):\n",
    "    corners = cv2.cornerHarris(image.astype(np.float32), blockSize=2, ksize=3, k=0.04)\n",
    "    corners = cv2.dilate(corners, None)\n",
    "    corner_count = np.sum(corners > 0.01 * corners.max())\n",
    "    return corner_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5c8b6abe-144c-4472-a870-2de9067116ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of Intersections\n",
    "def compute_intersections(image):\n",
    "    binary_image = image > np.mean(image)\n",
    "    skeleton = morphology.skeletonize(binary_image)\n",
    "    labeled_image = label(skeleton)\n",
    "    intersections = 0\n",
    "    for region in regionprops(labeled_image):\n",
    "        if region.area > 3:\n",
    "            intersections += 1\n",
    "    \n",
    "    return intersections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b81b622d-06b3-496d-bcd3-18cbccccf60f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aspect Ratio\n",
    "def compute_aspect_ratio(image):\n",
    "    _, _, width, height = cv2.boundingRect(image)\n",
    "    aspect_ratio = width / float(height)\n",
    "    return aspect_ratio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "708cca81-7c8d-42dd-af9d-bba62499c883",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Enclosed Areas\n",
    "def compute_enclosed_areas(image):\n",
    "    labeled_image = label(image)\n",
    "    regions = regionprops(labeled_image)\n",
    "    enclosed_areas = len([region for region in regions if region.area > 100]) \n",
    "    return enclosed_areas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d45a0ff8-8fb7-4e16-8eca-c9a5dbf873ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Straight Lines\n",
    "def compute_straight_lines(image):\n",
    "    lines = probabilistic_hough_line(image, threshold=10, line_length=5, line_gap=3)\n",
    "    line_count = len(lines)\n",
    "    return line_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3f75a624-e278-4db3-a36b-65c5f8fa9f87",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This function extracts the features from the images shown in the MNIST dataset\n",
    "def extract_features(X):\n",
    "    features = []\n",
    "    for idx in range(len(X)):\n",
    "        image = X.iloc[idx].values.reshape(28, 28).astype(np.uint8)\n",
    "        \n",
    "        dark_pixels = num_dark_pixels(image)\n",
    "        vert_sym = vertical_symmetry(image)\n",
    "        horiz_sym = horizontal_symmetry(image)\n",
    "        aspect_ratio = compute_aspect_ratio(image)\n",
    "        corner_count = compute_corners(image)\n",
    "        intersections = compute_intersections(image)\n",
    "        line_count = compute_straight_lines(image)\n",
    "        enclosed_areas = compute_enclosed_areas(image)\n",
    "        \n",
    "        features.append([dark_pixels, vert_sym, horiz_sym, aspect_ratio, corner_count, intersections, line_count, enclosed_areas])\n",
    "    return features\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "429fcfdf-b9d7-473a-81b1-44dc2f674e83",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 36.98%\n"
     ]
    }
   ],
   "source": [
    "# This final cell splits the data into training and testing, and then stores extracted features in a dataframe for X and y training data. \n",
    "# An average feature vector for digits 0-9 is created by finding an average of each features for each digit\n",
    "# Weights are then added to the features and then to the average feature vector for each digit\n",
    "# The features are then extracted for testing data with weights and stored in another dataframe\n",
    "# The distance (Euclidean Distance) is calculated between the actual features of the image and the average feature vector\n",
    "# To do this, I created a function called \"classify_image\" and added the weight changes to it (Had to learn what 'linalg' does for Euclidean distance)\n",
    "# Finally, by applying \"classify_image\" and converting a row from the testing dataframe into an array using Numpy, I was able to convert all the rows into a series in 'y_pred'\n",
    "# The accuracy score was then calculated in percentage\n",
    "feature_weights = np.array([1, 1.1, 1.1, 1, 1, 1, 1, 1])\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, random_state=1000000)\n",
    "\n",
    "train_features = extract_features(X_train)\n",
    "train_df = pd.DataFrame(train_features, columns=['num_dark_pixels', 'vertical_symmetry', 'horizontal_symmetry', 'aspect_ratio', 'corners', 'intersections', 'straight_lines', 'enclosed_areas'])\n",
    "train_df['label'] = y_train.values\n",
    "\n",
    "average_feature_vectors = train_df.groupby('label').mean()\n",
    "\n",
    "test_features = extract_features(X_test)\n",
    "test_df = pd.DataFrame(test_features, columns=['num_dark_pixels', 'vertical_symmetry', 'horizontal_symmetry', 'aspect_ratio', 'corners', 'intersections', 'straight_lines', 'enclosed_areas'])\n",
    "\n",
    "def classify_image(image_features, average_feature_vectors, feature_weights):\n",
    "    weighted_average_vectors = average_feature_vectors.values * feature_weights\n",
    "    weighted_image_features = image_features * feature_weights\n",
    "    distances = np.linalg.norm(weighted_average_vectors - weighted_image_features, axis=1)\n",
    "    return average_feature_vectors.index[np.argmin(distances)]\n",
    "\n",
    "y_pred = test_df.apply(lambda row: classify_image(row.values, average_feature_vectors, feature_weights), axis=1)\n",
    "\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Accuracy: {accuracy * 100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6e2d0a9a-0c8f-4e8f-ad7c-a58647cc56eb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(56000, 784)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ce2b5d00-b1ab-4671-bd25-b8ab7f7dd862",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(56000,)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b195bdbe-2b84-45ed-835d-3dc675e2dd50",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(14000, 784)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "70aeda31-686c-4b4a-9b88-f5d20a7ce1e3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(14000,)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f5ae1b03-c07d-4bc0-b8c1-c4039baebc74",
   "metadata": {},
   "outputs": [],
   "source": [
    "# End of Program"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
